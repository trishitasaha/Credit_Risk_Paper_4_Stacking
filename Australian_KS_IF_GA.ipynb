{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa9b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in each class before oversampling:\n",
      "0    383\n",
      "1    307\n",
      "Name: 14, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trish\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1043: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=3\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in each class after oversampling:\n",
      "1    390\n",
      "0    383\n",
      "Name: 14, dtype: int64\n",
      "Number of outliers detected:\n",
      " 1    619\n",
      "-1    154\n",
      "dtype: int64\n",
      "Number of samples in each class after removing outliers:\n",
      "0    321\n",
      "1    298\n",
      "Name: 14, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('australian.dat', sep=' ', header=None)\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Print the number of samples in each class before oversampling\n",
    "print(\"Number of samples in each class before oversampling:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Perform KMeansSMOTE to oversample the minority class\n",
    "kmeans_smote = KMeansSMOTE(random_state=42, cluster_balance_threshold=0.2)\n",
    "X_resampled, y_resampled = kmeans_smote.fit_resample(X, y)\n",
    "\n",
    "# Print the number of samples in each class after oversampling\n",
    "print(\"Number of samples in each class after oversampling:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# Perform outlier detection using Isolation Forest\n",
    "iso_forest = IsolationForest(random_state=42, contamination='auto')\n",
    "y_outliers = iso_forest.fit_predict(X_resampled)\n",
    "\n",
    "# Print the number of outliers detected\n",
    "print(\"Number of outliers detected:\")\n",
    "print(pd.Series(y_outliers).value_counts())\n",
    "\n",
    "# Remove the outliers\n",
    "X_no_outliers = X_resampled[y_outliers == 1]\n",
    "y_no_outliers = y_resampled[y_outliers == 1]\n",
    "\n",
    "# Print the number of samples in each class after removing outliers\n",
    "print(\"Number of samples in each class after removing outliers:\")\n",
    "print(pd.Series(y_no_outliers).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177d15fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                               \n",
      "0  \t50    \t[-0.07538   4.94      0.178054]\t[ 0.459679  2.781438  0.06617 ]\t[-1.045155  1.        0.059859]\t[  0.534269  10.         0.322818]\n",
      "1  \t27    \t[-199.778174    6.8       200.188574]\t[ 1400.03172      2.465766  1399.973062]\t[-10000.            1.            0.048153]\t[     0.534269     11.        10000.      ]\n",
      "2  \t30    \t[-199.553663    8.02      200.149058]\t[ 1400.063768     1.760568  1399.978706]\t[-10000.            3.            0.095074]\t[     0.560215     12.        10000.      ]\n",
      "3  \t28    \t[ 0.487018  8.12      0.146276]      \t[ 0.15735   1.409113  0.035252]         \t[-0.300165  5.        0.051226]            \t[  0.560215  10.         0.277992]         \n",
      "4  \t36    \t[ 0.528264  8.14      0.151418]      \t[ 0.114465  1.113732  0.029314]         \t[-0.241808  5.        0.078037]            \t[  0.599039  10.         0.257698]         \n",
      "5  \t31    \t[-199.463288    8.18      200.1462  ]\t[ 1400.076674     1.052426  1399.979114]\t[-10000.            6.            0.081926]\t[     0.599039     11.        10000.      ]\n",
      "6  \t25    \t[ 0.549088  8.2       0.14285 ]      \t[ 0.089524  1.113553  0.024891]         \t[-0.022121  4.        0.03587 ]            \t[  0.599039  10.         0.190661]         \n",
      "7  \t31    \t[-199.455642    8.42      200.145327]\t[ 1400.077767     0.826801  1399.979239]\t[-10000.            7.            0.081926]\t[     0.599039     11.        10000.      ]\n",
      "8  \t26    \t[ 0.570434  8.54      0.147632]      \t[ 0.019226  0.669627  0.02183 ]         \t[ 0.515015  7.        0.078343]            \t[  0.61189   10.         0.194357]         \n",
      "9  \t34    \t[ 0.559677  8.16      0.140341]      \t[ 0.058209  0.902441  0.021301]         \t[ 0.197883  5.        0.087307]            \t[  0.61189   10.         0.183704]         \n",
      "10 \t24    \t[ 0.566666  8.32      0.139536]      \t[ 0.065269  0.733212  0.03035 ]         \t[ 0.139992  6.        0.082673]            \t[  0.61189   10.         0.280029]         \n",
      "11 \t22    \t[ 0.581926  8.38      0.136627]      \t[ 0.02169   0.628967  0.02738 ]         \t[ 0.508475  7.        0.082673]            \t[  0.61189   10.         0.182849]         \n",
      "12 \t29    \t[ 0.584616  8.3       0.128754]      \t[ 0.022542  0.538516  0.029851]         \t[ 0.50841   7.        0.082673]            \t[ 0.618462  9.        0.183841]            \n",
      "13 \t26    \t[ 0.588246  8.24      0.123972]      \t[ 0.024463  0.51225   0.022694]         \t[ 0.508515  7.        0.071982]            \t[ 0.618462  9.        0.171128]            \n",
      "14 \t28    \t[ 0.588754  8.26      0.116408]      \t[ 0.018903  0.52192   0.019438]         \t[ 0.547169  8.        0.074025]            \t[  0.618462  10.         0.159896]         \n",
      "15 \t31    \t[ 0.578408  8.18      0.118079]      \t[ 0.058473  0.477074  0.023115]         \t[ 0.191611  8.        0.082673]            \t[  0.618462  10.         0.21776 ]         \n",
      "16 \t24    \t[ 0.589803  8.04      0.119218]      \t[ 0.022881  0.397995  0.017598]         \t[ 0.495381  7.        0.082673]            \t[ 0.618462  9.        0.180622]            \n",
      "17 \t23    \t[ 0.57959   7.86      0.118379]      \t[ 0.078782  0.4005    0.027095]         \t[ 0.06258   6.        0.082621]            \t[ 0.618462  8.        0.291066]            \n",
      "18 \t38    \t[ 0.569351  8.        0.116099]      \t[ 0.096318  0.52915   0.022541]         \t[-0.086377  6.        0.075426]            \t[  0.618462  10.         0.234906]         \n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "estimator = ExtraTreesClassifier()\n",
    "\n",
    "selector = GeneticSelectionCV(estimator,cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=\"r2\", \n",
    "                                  max_features=10,\n",
    "                                  n_population=50,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=40,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.05,\n",
    "                                  tournament_size=3,\n",
    "                                  n_gen_no_change=10,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)\n",
    "selector = selector.fit(X_no_outliers, y_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d971d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm result:\n",
      "[False  True  True False  True False False  True False False  True  True\n",
      "  True  True]\n",
      "List of important features :\n",
      "Int64Index([1, 2, 4, 7, 10, 11, 12, 13], dtype='int64')\n",
      "List of less important features :\n",
      "Int64Index([0, 3, 5, 6, 8, 9], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print('Genetic algorithm result:')\n",
    "print(selector.support_)\n",
    "X_no_outliers = pd.DataFrame(X_no_outliers, columns=X.columns)\n",
    "print('List of important features :')\n",
    "print(X_no_outliers.columns[selector.support_])\n",
    "print('List of less important features :')\n",
    "print(X_no_outliers.columns[~selector.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fa1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
